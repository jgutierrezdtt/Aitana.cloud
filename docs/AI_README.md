# ğŸ¤– IntegraciÃ³n de IA en Aitana.cloud

## ğŸ“‹ Resumen

Se ha integrado **IA open-source** en el evaluador de madurez SSDLC con soporte para:

- âœ… **Ollama local** (desarrollo, gratis, privado)
- âœ… **Together AI** (producciÃ³n, 8B tokens gratis)
- âœ… **Groq** (alternativa ultra rÃ¡pida, gratis en beta)
- âœ… **OpenAI** (fallback compatible)

---

## ğŸ¯ Funcionalidades Implementadas

### 1. AnÃ¡lisis Inteligente de Respuestas
**UbicaciÃ³n**: Tarjeta de cada dominio en `/evaluacion-madurez`

**QuÃ© hace**:
- Analiza las respuestas del usuario en cada dominio
- EvalÃºa el nivel de madurez (1-5)
- Identifica los 3 gaps crÃ­ticos
- Genera 3 recomendaciones priorizadas con plazos

**CÃ³mo funciona**:
1. Usuario responde preguntas de un dominio
2. Click en botÃ³n "ğŸ¤– AnÃ¡lisis Inteligente"
3. La IA analiza respuestas considerando el sector
4. Muestra insights personalizados

### 2. API Endpoints

```bash
# AnÃ¡lisis de evaluaciÃ³n SSDLC
POST /api/ai/analyze
Content-Type: application/json

{
  "domain": "Governance",
  "responses": {
    "gov-1": true,
    "gov-2": false,
    "gov-3": true
  },
  "sector": "financiero"
}

# Respuesta
{
  "success": true,
  "analysis": "### Nivel de Madurez: 2 - Gestionado\n...",
  "metadata": {
    "provider": "ollama",
    "model": "qwen2.5:7b",
    "timestamp": "2025-12-06T10:30:00.000Z"
  }
}
```

```bash
# Chat de consultorÃ­a normativa
POST /api/ai/chat
Content-Type: application/json

{
  "question": "Â¿CÃ³mo implementar controles DORA en un banco?",
  "context": "Banco mediano, 500 empleados, EspaÃ±a"
}
```

---

## ğŸš€ InstalaciÃ³n

### OpciÃ³n A: Desarrollo Local (Ollama)

```bash
# 1. Instalar Ollama
brew install ollama

# 2. Iniciar servidor
ollama serve

# 3. En otra terminal, descargar modelo
ollama pull qwen2.5:7b  # 4GB, recomendado

# 4. Iniciar Next.js
npm run dev

# 5. Probar en http://localhost:3000/evaluacion-madurez
```

### OpciÃ³n B: ProducciÃ³n (Together AI)

```bash
# 1. Registrarse en https://together.ai (gratis)
# 2. Obtener API Key en Dashboard â†’ API Keys
# 3. Configurar variables de entorno

# Local (.env.local)
echo 'TOGETHER_API_KEY=tu_key_aqui' >> .env.local
echo 'TOGETHER_BASE_URL=https://api.together.xyz/v1' >> .env.local
echo 'TOGETHER_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo' >> .env.local

# Vercel (producciÃ³n)
vercel env add TOGETHER_API_KEY production
vercel env add TOGETHER_BASE_URL production
vercel env add TOGETHER_MODEL production
vercel --prod
```

---

## ğŸ“ Archivos Creados

### Core

1. **`/src/lib/ai/aiClient.ts`** (280 lÃ­neas)
   - Cliente universal de IA
   - `queryAI()`: FunciÃ³n principal
   - `analyzeSSLDCResponses()`: AnÃ¡lisis especializado
   - `queryNormativaAssistant()`: Chatbot de consultorÃ­a
   - `generateActionPlan()`: Generador de roadmaps
   - Auto-fallback: Ollama â†’ Together AI â†’ Groq â†’ OpenAI

2. **`/src/app/api/ai/analyze/route.ts`** (40 lÃ­neas)
   - API endpoint para anÃ¡lisis de evaluaciones
   - Edge runtime (rÃ¡pido en Vercel)
   - ValidaciÃ³n de inputs
   - Error handling completo

3. **`/src/app/api/ai/chat/route.ts`** (35 lÃ­neas)
   - API endpoint para chat de consultorÃ­a
   - Compatible con streaming futuro
   - Rate limiting ready

### UI Components

4. **`/src/components/evaluacion/AIInsightsButton.tsx`** (100 lÃ­neas)
   - BotÃ³n con estados (loading, error, success)
   - ExpansiÃ³n/colapso de insights
   - Accessibilidad completa (ARIA, keyboard)
   - Iconos animados (Sparkles, Loader2)

5. **`/src/hooks/useAIAnalysis.ts`** (60 lÃ­neas)
   - `useAIAnalysis()`: Hook para anÃ¡lisis
   - `useAIChat()`: Hook para chatbot
   - Manejo de estados (loading, error)
   - TypeScript estricto

### DocumentaciÃ³n

6. **`/docs/AI_INTEGRATION.md`** (400+ lÃ­neas)
   - GuÃ­a completa de integraciÃ³n
   - Ejemplos de cÃ³digo
   - Comparativa de proveedores
   - Troubleshooting detallado
   - Seguridad y rate limiting

7. **`/docs/AI_QUICKSTART.md`** (300+ lÃ­neas)
   - Inicio rÃ¡pido (5 minutos)
   - Comandos copy-paste
   - VerificaciÃ³n paso a paso
   - Checklist de implementaciÃ³n

8. **`/scripts/setup-ai.sh`** (80 lÃ­neas)
   - Script de instalaciÃ³n automÃ¡tica
   - Configura variables de entorno
   - Instrucciones interactivas
   - Compatible con macOS/Linux

### Actualizaciones

9. **`/src/components/evaluacion/ResultsDashboard.tsx`** (modificado)
   - Importa `AIInsightsButton`
   - Integrado en cada tarjeta de dominio
   - Pasa contexto completo al anÃ¡lisis

---

## ğŸ”§ ConfiguraciÃ³n

### Variables de Entorno

**Desarrollo Local (`.env.local`)**

```env
# Ollama Local (Recomendado para desarrollo)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b

# ProducciÃ³n - Together AI (8B tokens gratis)
TOGETHER_API_KEY=your_together_key
TOGETHER_BASE_URL=https://api.together.xyz/v1
TOGETHER_MODEL=meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo

# Alternativa - Groq (ultra rÃ¡pido)
GROQ_API_KEY=your_groq_key
GROQ_BASE_URL=https://api.groq.com/openai/v1
GROQ_MODEL=llama-3.2-3b-preview

# Fallback - OpenAI (requiere pago)
OPENAI_API_KEY=your_openai_key
```

**Vercel (ProducciÃ³n)**

En Dashboard â†’ Settings â†’ Environment Variables:
- `TOGETHER_API_KEY`
- `TOGETHER_BASE_URL`
- `TOGETHER_MODEL`

---

## ğŸ§ª Testing

### Test Manual

```bash
# 1. Abrir evaluador
open http://localhost:3000/evaluacion-madurez

# 2. Seleccionar sector (ej: Financiero)
# 3. Responder 5-10 preguntas del dominio Governance
# 4. Click en "ğŸ¤– AnÃ¡lisis Inteligente"
# 5. Verificar respuesta de IA en espaÃ±ol
```

### Test con cURL

```bash
# Probar endpoint directamente
curl -X POST http://localhost:3000/api/ai/analyze \
  -H "Content-Type: application/json" \
  -d '{
    "domain": "Governance",
    "responses": {
      "gov-policy-1": true,
      "gov-roles-1": false,
      "gov-training-1": true
    },
    "sector": "financiero"
  }' | jq

# Respuesta esperada (200 OK)
{
  "success": true,
  "analysis": "### Nivel de Madurez: 2 - Gestionado\n\n[JustificaciÃ³n del nivel]\n\n### Gaps CrÃ­ticos...",
  "metadata": {
    "provider": "ollama",
    "model": "qwen2.5:7b",
    "timestamp": "2025-12-06T12:34:56.789Z"
  }
}
```

### Test de Fallback

```bash
# Detener Ollama
pkill ollama

# Reiniciar Next.js (deberÃ­a usar Together AI)
npm run dev

# Probar endpoint - deberÃ­a funcionar con cloud provider
curl -X POST http://localhost:3000/api/ai/analyze ...
```

---

## ğŸ“Š Arquitectura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                  Next.js Frontend                        â”‚
â”‚                                                           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ ResultsDashboard.tsx                           â”‚     â”‚
â”‚  â”‚   â””â”€> AIInsightsButton.tsx                     â”‚     â”‚
â”‚  â”‚        â””â”€> useAIAnalysis() hook                â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â”‚                               â”‚
â”‚                          â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚  â”‚ POST /api/ai/analyze                           â”‚     â”‚
â”‚  â”‚  - ValidaciÃ³n                                  â”‚     â”‚
â”‚  â”‚  - Edge runtime                                â”‚     â”‚
â”‚  â”‚  - Error handling                              â”‚     â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                          â”‚                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ /src/lib/ai/aiClient.ts â”‚
              â”‚  - queryAI()            â”‚
              â”‚  - Smart fallback       â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
           â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
           â–¼               â–¼               â–¼
    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚ Ollama   â”‚   â”‚ Together AI â”‚  â”‚   Groq   â”‚
    â”‚  Local   â”‚   â”‚   Cloud     â”‚  â”‚  Cloud   â”‚
    â”‚  :11434  â”‚   â”‚  REST API   â”‚  â”‚ REST API â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
       Dev            Prod             Fallback
```

---

## ğŸ’° Costos

### Gratis (Tier Gratuito)

| Proveedor | LÃ­mite Gratis | Renovable |
|-----------|---------------|-----------|
| **Ollama Local** | Ilimitado | âœ… Siempre |
| **Together AI** | 8B tokens | âŒ Una vez |
| **Groq** | 30 req/min | âœ… En beta |

### De Pago (Cuando se agote gratis)

| Proveedor | Costo/1M tokens | Velocidad |
|-----------|-----------------|-----------|
| Together AI | $0.20 | âš¡âš¡âš¡ |
| Groq | TBD (en beta) | âš¡âš¡âš¡âš¡âš¡ |
| OpenAI GPT-3.5 | $0.50 | âš¡âš¡âš¡ |
| OpenAI GPT-4 | $15.00 | âš¡âš¡ |

**EstimaciÃ³n para 1000 usuarios/mes**:
- 5 anÃ¡lisis por usuario = 5000 requests
- ~1000 tokens por anÃ¡lisis = 5M tokens
- Costo con Together AI = $1.00/mes
- Costo con Ollama local = $0

---

## ğŸ”’ Seguridad

### Implementado

- âœ… ValidaciÃ³n de inputs en API
- âœ… Error handling sin exponer detalles
- âœ… Edge runtime (aislamiento)
- âœ… Variables de entorno seguras
- âœ… CORS configurado en Vercel

### Recomendado Agregar

```bash
# Rate limiting con Upstash
npm install @upstash/ratelimit @upstash/redis

# Registrarse: https://upstash.com (gratis)
# Agregar a middleware.ts
```

---

## ğŸ› Troubleshooting

### "Cannot connect to Ollama"

```bash
# Verificar que estÃ¡ corriendo
ps aux | grep ollama

# Si no, iniciarlo
ollama serve

# Verificar puerto
lsof -i :11434
# DeberÃ­a mostrar: ollama
```

### "Model not found"

```bash
# Listar modelos instalados
ollama list

# Descargar si falta
ollama pull qwen2.5:7b
```

### "API key not configured"

```bash
# Verificar .env.local
cat .env.local | grep -E "TOGETHER|GROQ|OPENAI"

# Reiniciar Next.js para cargar cambios
pkill -f "next dev"
npm run dev
```

### Respuestas en inglÃ©s (esperabas espaÃ±ol)

El prompt ya incluye "Responde en espaÃ±ol". Si sigue en inglÃ©s:
1. Modelo incorrecto (usar qwen2.5:7b o mistral:7b)
2. Temperatura muy alta (verificar en aiClient.ts)
3. Contexto en inglÃ©s (revisar inputs)

---

## ğŸ“š Referencias

- **Ollama**: https://ollama.com
- **Together AI**: https://together.ai
- **Groq**: https://console.groq.com
- **OpenAI SDK**: https://github.com/openai/openai-node
- **Vercel Edge Runtime**: https://vercel.com/docs/functions/edge-functions

---

## âœ… Checklist de ImplementaciÃ³n

- [x] CÃ³digo creado
  - [x] Cliente de IA (`aiClient.ts`)
  - [x] API endpoints (`/api/ai/*`)
  - [x] Hooks React (`useAIAnalysis`)
  - [x] UI Component (`AIInsightsButton`)
  - [x] IntegraciÃ³n en dashboard

- [ ] ConfiguraciÃ³n local
  - [ ] Ollama instalado
  - [ ] Modelo descargado
  - [ ] Variables en `.env.local`
  - [ ] Next.js corriendo

- [ ] Testing
  - [ ] BotÃ³n visible en UI
  - [ ] Click funciona sin errores
  - [ ] Respuesta en espaÃ±ol
  - [ ] Consola sin errores

- [ ] ProducciÃ³n (opcional)
  - [ ] Cuenta Together AI
  - [ ] API Key configurada
  - [ ] Variables en Vercel
  - [ ] Deploy exitoso

---

## ğŸ¯ PrÃ³ximos Pasos

### Mejoras Futuras

1. **Streaming de respuestas**
   ```typescript
   // En lugar de esperar respuesta completa
   // mostrar palabra por palabra
   const stream = await queryAI(prompt, { stream: true });
   ```

2. **Chatbot conversacional**
   ```typescript
   // Chat con historial de mensajes
   const messages = [
     { role: 'system', content: 'Eres un consultor...' },
     { role: 'user', content: 'Pregunta 1' },
     { role: 'assistant', content: 'Respuesta 1' },
     { role: 'user', content: 'Pregunta 2' }
   ];
   ```

3. **AnÃ¡lisis de documentos**
   ```typescript
   // Upload PDF de polÃ­tica de seguridad
   // IA analiza cumplimiento contra normativas
   ```

4. **GeneraciÃ³n de informes**
   ```typescript
   // Export PDF con insights de IA
   // Formato ejecutivo + tÃ©cnico
   ```

5. **Benchmarking con IA**
   ```typescript
   // Comparar tu evaluaciÃ³n con industria
   // Usando datos agregados anÃ³nimos
   ```

---

**Â¿Problemas?** Revisa `/docs/AI_INTEGRATION.md` o `/docs/AI_QUICKSTART.md`
